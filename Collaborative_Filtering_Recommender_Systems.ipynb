{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1y37MSCWnPw3FHqR6VHBFBsyeP3UHgktI",
      "authorship_tag": "ABX9TyMn7/YXv7QObrVFXb/Ltu8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Takeitiz/Machine-Learning/blob/main/Collaborative_Filtering_Recommender_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vu2a9flRSNun"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "import pandas as pd \n",
        "%matplotlib inline \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/work1/data/small_movies_X.csv', 'rb')\n",
        "X = np.loadtxt(file, delimiter = \",\")\n",
        "file = open('/content/drive/MyDrive/work1/data/small_movies_W.csv', 'rb')\n",
        "W = loadtxt(file,delimiter = \",\")\n",
        "file = open('/content/drive/MyDrive/work1/data/small_movies_b.csv', 'rb')\n",
        "b = loadtxt(file,delimiter = \",\")\n",
        "b = b.reshape(1,-1)\n",
        "num_movies, num_features = X.shape\n",
        "num_users,_ = W.shape"
      ],
      "metadata": {
        "id": "yhzpENjMURzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/work1/data/small_movies_Y.csv', 'rb')\n",
        "Y = loadtxt(file,delimiter = \",\")\n",
        "file = open('/content/drive/MyDrive/work1/data/small_movies_R.csv', 'rb')\n",
        "R = loadtxt(file,delimiter = \",\")"
      ],
      "metadata": {
        "id": "9H8HHaoSSgWv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Y\", Y.shape, \"R\", R.shape)\n",
        "print(\"X\", X.shape)\n",
        "print(\"W\", W.shape)\n",
        "print(\"b\", b.shape)\n",
        "print(\"num_features\", num_features)\n",
        "print(\"num_movies\",   num_movies)\n",
        "print(\"num_users\",    num_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0kVX7c_SuB2",
        "outputId": "cf446327-baf6-4572-c5c9-680420eedabc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y (4778, 443) R (4778, 443)\n",
            "X (4778, 10)\n",
            "W (443, 10)\n",
            "b (1, 443)\n",
            "num_features 10\n",
            "num_movies 4778\n",
            "num_users 443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
        "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d68kUHePS7LX",
        "outputId": "798e8560-0885-43e1-addc-245d1e1114c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rating for movie 1 : 3.400 / 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
        "  nm, nu = Y.shape\n",
        "  J = 0\n",
        "  for i in range(nu):\n",
        "    w = W[i]\n",
        "    b_i = b[0,i]\n",
        "    for j in range(nm):\n",
        "      x = X[j]\n",
        "      y = Y[j, i]\n",
        "      r = R[j, i]\n",
        "      J += np.square(r * (np.dot(w,x) + b_i - y))\n",
        "  J = J/2\n",
        "  J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
        "  return J"
      ],
      "metadata": {
        "id": "e3r0_7BETm-C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users_r = 4\n",
        "num_movies_r = 5 \n",
        "num_features_r = 3\n",
        "X_r = X[:num_movies_r, :num_features_r]\n",
        "W_r = W[:num_users_r,  :num_features_r]\n",
        "b_r = b[0, :num_users_r].reshape(1,-1)\n",
        "Y_r = Y[:num_movies_r, :num_users_r]\n",
        "R_r = R[:num_movies_r, :num_users_r]\n",
        "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
        "print(f\"Cost: {J:0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWWddEPpYTwU",
        "outputId": "c5cec698-36a2-40e4-f09d-0326e424ad23"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 13.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
        "  j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
        "  J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
        "  return J "
      ],
      "metadata": {
        "id": "v8tS9yWVczBm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movieList_df = pd.read_csv('/content/drive/MyDrive/work1/data/small_movie_list.csv', header=0, index_col=0,  delimiter=',', quotechar='\"')\n",
        "movieList = movieList_df[\"title\"].to_list()"
      ],
      "metadata": {
        "id": "BzpJP0wydjnd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_ratings = np.zeros(num_movies)\n",
        "my_ratings[2700] = 5 \n",
        "my_ratings[2609] = 2\n",
        "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
        "my_ratings[246]  = 5   # Shrek (2001)\n",
        "my_ratings[2716] = 3   # Inception\n",
        "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
        "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
        "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
        "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
        "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
        "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
        "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
        "my_ratings[793]  = 5 \n",
        "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4QDI_eexdz",
        "outputId": "3b1c03b3-9fa6-449e-a8dd-1831e7cf8dc1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[246, 366, 382, 622, 793, 929, 988, 1150, 2609, 2700, 2716, 2925, 2937]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/work1/data/small_movies_Y.csv', 'rb')\n",
        "Y = loadtxt(file,delimiter = \",\")\n",
        "file = open('/content/drive/MyDrive/work1/data/small_movies_R.csv', 'rb')\n",
        "R = loadtxt(file,delimiter = \",\")\n",
        "Y    = np.c_[my_ratings, Y]\n",
        "R    = np.c_[(my_ratings != 0).astype(int), R]"
      ],
      "metadata": {
        "id": "JAo0_K2lgOVF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
        "Ynorm = Y - np.multiply(Ymean, R)"
      ],
      "metadata": {
        "id": "jbBYBG6JgRj_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_movies, num_users = Y.shape\n",
        "num_features = 100\n",
        "tf.random.set_seed(1234) # for consistent results\n",
        "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
        "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
        "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
      ],
      "metadata": {
        "id": "Gt4omaaMgbaY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 200\n",
        "lambda_ = 1\n",
        "for iter in range(iterations):\n",
        "  with tf.GradientTape() as tape:\n",
        "    cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
        "  grads = tape.gradient(cost_value, [X,W,b])\n",
        "  optimizer.apply_gradients(zip(grads, [X,W,b]))\n",
        "  if iter % 20 == 0:\n",
        "    print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiHeCOIUg4ei",
        "outputId": "db5772e5-fdd2-4cd4-aabf-6809af818891"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss at iteration 0: 2321191.3\n",
            "Training loss at iteration 20: 136168.7\n",
            "Training loss at iteration 40: 51863.3\n",
            "Training loss at iteration 60: 24598.8\n",
            "Training loss at iteration 80: 13630.4\n",
            "Training loss at iteration 100: 8487.6\n",
            "Training loss at iteration 120: 5807.7\n",
            "Training loss at iteration 140: 4311.6\n",
            "Training loss at iteration 160: 3435.2\n",
            "Training loss at iteration 180: 2902.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
        "pm = p + Ymean\n",
        "my_predictions = pm[:,0]\n",
        "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
        "for i in range(17):\n",
        "    j = ix[i]\n",
        "    if j not in my_rated:\n",
        "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
        "\n",
        "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0:\n",
        "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vodkOCtJiUm4",
        "outputId": "747b821a-ca2b-4bf5-ea9c-488b59bbdbbe"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting rating 4.49 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
            "Predicting rating 4.48 for movie Martin Lawrence Live: Runteldat (2002)\n",
            "Predicting rating 4.48 for movie Memento (2000)\n",
            "Predicting rating 4.47 for movie Delirium (2014)\n",
            "Predicting rating 4.47 for movie Laggies (2014)\n",
            "Predicting rating 4.47 for movie One I Love, The (2014)\n",
            "Predicting rating 4.46 for movie Particle Fever (2013)\n",
            "Predicting rating 4.45 for movie Eichmann (2007)\n",
            "Predicting rating 4.45 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
            "Predicting rating 4.45 for movie Into the Abyss (2011)\n",
            "\n",
            "\n",
            "Original vs Predicted ratings:\n",
            "\n",
            "Original 5.0, Predicted 4.90 for Shrek (2001)\n",
            "Original 5.0, Predicted 4.84 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Original 2.0, Predicted 2.13 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "Original 5.0, Predicted 4.88 for Harry Potter and the Chamber of Secrets (2002)\n",
            "Original 5.0, Predicted 4.87 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
            "Original 3.0, Predicted 3.00 for Eternal Sunshine of the Spotless Mind (2004)\n",
            "Original 5.0, Predicted 4.90 for Incredibles, The (2004)\n",
            "Original 2.0, Predicted 2.11 for Persuasion (2007)\n",
            "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
            "Original 3.0, Predicted 3.00 for Inception (2010)\n",
            "Original 1.0, Predicted 1.41 for Louis Theroux: Law & Disorder (2008)\n",
            "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien à déclarer) (2010)\n"
          ]
        }
      ]
    }
  ]
}